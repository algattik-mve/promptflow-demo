id: qna_over_patents
name: QnA solution over patents dataset
environment:
  python_requirements_txt: requirements.txt
inputs:
  question:
    type: string
    default: When should cruise control automatically switch off?
    is_chat_input: false
outputs:
  output:
    type: string
    reference: ${answer_the_question_with_context.output}
  context:
    type: string
    reference: ${generate_prompt_context.output}
  search_result:
    type: string
    reference: ${generate_document_list.output}
nodes:
- name: embed_the_question
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: open_ai_connection
    deployment_name: text-embedding-ada-002
    input: ${inputs.question}
  use_variants: false
- name: search_question_from_vector_db
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.vector_db_lookup.VectorDBLookup.search
  inputs:
    connection: ai_search_connection
    index_name: patents
    text_field: ""
    vector_field: contentVector
    top_k: 2
    vector: ${embed_the_question.output}
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${search_question_from_vector_db.output}
  use_variants: false
- name: answer_the_question_with_context
  use_variants: true
- name: generate_document_list
  type: python
  source:
    type: code
    path: generate_document_list.py
  inputs:
    search_result: ${search_question_from_vector_db.output}
node_variants:
  answer_the_question_with_context:
    default_variant_id: variant_0
    variants:
      variant_0:
        node:
          type: llm
          source:
            type: code
            path: qna_prompt_1.jinja2
          inputs:
            deployment_name: gpt-35-turbo
            temperature: 0
            top_p: 1
            max_tokens: 1000
            presence_penalty: 0
            frequency_penalty: 0
            question: ${inputs.question}
            contexts: ${generate_prompt_context.output}
          provider: AzureOpenAI
          connection: open_ai_connection
          api: chat
          module: promptflow.tools.aoai
          use_variants: false
      variant_1:
        node:
          type: llm
          source:
            type: code
            path: qna_prompt_2.jinja2
          inputs:
            deployment_name: gpt-35-turbo
            temperature: 0
            top_p: 1
            max_tokens: 1000
            presence_penalty: 0
            frequency_penalty: 0
            question: ${inputs.question}
            contexts: ${generate_prompt_context.output}
          provider: AzureOpenAI
          connection: open_ai_connection
          api: chat
          module: promptflow.tools.aoai
          use_variants: false
      variant_2:
        node:
          type: llm
          source:
            type: code
            path: qna_prompt_2.jinja2
          inputs:
            deployment_name: gpt-35-turbo
            temperature: 0.9
            top_p: 1
            max_tokens: 1000
            presence_penalty: 0
            frequency_penalty: 0
            question: ${inputs.question}
            contexts: ${generate_prompt_context.output}
          provider: AzureOpenAI
          connection: open_ai_connection
          api: chat
          module: promptflow.tools.aoai
          use_variants: false
